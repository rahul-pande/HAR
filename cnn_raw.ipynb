{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import SeparableConv1D, Conv1D, MaxPooling1D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from keras_helper import PlotProgress\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(Y, Y_hat):\n",
    "    report = classification_report(\n",
    "        y_true=Y.argmax(axis=1),\n",
    "        y_pred=Y_hat.argmax(axis=1),\n",
    "        labels=list(label_mapping.keys()),\n",
    "        target_names=list(label_mapping.values())\n",
    "    )\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class PlotProgress(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, entity='loss'):\n",
    "        self.entity = entity\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('{}'.format(self.entity)))\n",
    "        self.val_losses.append(logs.get('val_{}'.format(self.entity)))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"{}\".format(self.entity))\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_{}\".format(self.entity))\n",
    "        plt.legend()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_acc_x_train = pd.read_csv('../data/har/train/Inertial_Signals/body_acc_x_train.txt', sep='\\s+', header=None)\n",
    "body_acc_y_train = pd.read_csv('../data/har/train/Inertial_Signals/body_acc_y_train.txt', sep='\\s+', header=None)\n",
    "body_acc_z_train = pd.read_csv('../data/har/train/Inertial_Signals/body_acc_z_train.txt', sep='\\s+', header=None)\n",
    "\n",
    "total_acc_x_train = pd.read_csv('../data/har/train/Inertial_Signals/total_acc_x_train.txt', sep='\\s+', header=None)\n",
    "total_acc_y_train = pd.read_csv('../data/har/train/Inertial_Signals/total_acc_y_train.txt', sep='\\s+', header=None)\n",
    "total_acc_z_train = pd.read_csv('../data/har/train/Inertial_Signals/total_acc_z_train.txt', sep='\\s+', header=None)\n",
    "\n",
    "body_gyro_x_train = pd.read_csv('../data/har/train/Inertial_Signals/body_gyro_x_train.txt', sep='\\s+', header=None)\n",
    "body_gyro_y_train = pd.read_csv('../data/har/train/Inertial_Signals/body_gyro_y_train.txt', sep='\\s+', header=None)\n",
    "body_gyro_z_train = pd.read_csv('../data/har/train/Inertial_Signals/body_gyro_z_train.txt', sep='\\s+', header=None)\n",
    "\n",
    "y_train = pd.read_csv('../data/har/train/y_train.txt', sep='\\s+', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "label_info = pd.read_csv('../data/har/activity_labels.txt', sep='\\s+', header=None)\n",
    "label_mapping = dict()\n",
    "\n",
    "for index, row_data in label_info.iterrows():\n",
    "    label_mapping.update({row_data[0] -1 : row_data[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'WALKING',\n",
       " 1: 'WALKING_UPSTAIRS',\n",
       " 2: 'WALKING_DOWNSTAIRS',\n",
       " 3: 'SITTING',\n",
       " 4: 'STANDING',\n",
       " 5: 'LAYING'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack([body_acc_x_train,\n",
    "                    body_acc_y_train,\n",
    "                    body_acc_z_train,\n",
    "                    total_acc_x_train,\n",
    "                    total_acc_y_train,\n",
    "                    total_acc_z_train,\n",
    "                    body_gyro_x_train,\n",
    "                    body_gyro_y_train,\n",
    "                    body_gyro_z_train,\n",
    "                   ], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories='auto')\n",
    "Y_train = encoder.fit_transform(y_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "Y_train = Y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, \n",
    "                                                      Y_train,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main Model\n",
    "# kernel_size = 32\n",
    "# max_pool_size = 3\n",
    "# dropout_rate = 0.25\n",
    "\n",
    "# input_sample_size = X_train.shape[1:]\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(30, kernel_size, padding='same', input_shape=input_sample_size))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size= max_pool_size))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# model.add(Conv1D(30, kernel_size, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size= max_pool_size))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 32\n",
    "max_pool_size = 3\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_sample_size = X_train.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size, padding='same', input_shape=input_sample_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size= max_pool_size))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv1D(16, kernel_size, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size= max_pool_size))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "plot_progress = PlotProgress(entity='acc')\n",
    "\n",
    "save_path = './keras-saves/_latest.ckpt'\n",
    "try:\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              callbacks=[plot_progress],\n",
    "              shuffle=True,\n",
    "         )\n",
    "except KeyboardInterrupt:\n",
    "#     model.save(save_path)\n",
    "    print('\\nOutput saved to: \"{}./*\"'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Confusion Matrix\\n\", get_confusion_matrix(Y_train, model.predict(X_train)))\n",
    "print(\"Validation Confusion Matrix\\n\", get_confusion_matrix(Y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "layer_name = 'conv1d_16'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = layer_dict[layer_name].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict[layer_name].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='../model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean_spectrogram = spects.groupby(y_train).apply(lambda group: np.mean([specg for frequencies, times, specg in group], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in grouped_mean_spectrogram.index:\n",
    "    plt.subplot(2, 3, i)\n",
    "#     plt.yticks(frequencies)\n",
    "    plt.imshow(grouped_mean_spectrogram[i], cmap='plasma')\n",
    "    plt.title(label_mapping.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "sample = 10\n",
    "cat = 4\n",
    "\n",
    "for i, (freqs, times, spec) in enumerate(spects.groupby(y_train).get_group(cat)[:sample]):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.yticks(freqs)\n",
    "    plt.imshow(spec, cmap='plasma')\n",
    "    plt.title(label_mapping.get(cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
